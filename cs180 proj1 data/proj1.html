<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 Project 1 — Prokudin‑Gorskii Colorizing</title>
  <style>
    :root { --fg:#0f172a; --muted:#475569; --link:#2563eb; --bg:#ffffff; --border:#e2e8f0; --card:#f8fafc; }
    * { box-sizing: border-box; }
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 0; color: var(--fg); background: var(--bg); }
    header { padding: 28px 20px; background: linear-gradient(180deg, #eef2ff, #ffffff); border-bottom: 1px solid var(--border); }
    .container { max-width: 980px; margin: 0 auto; padding: 0 20px; }
    h1 { margin: 0 0 8px; font-size: 28px; }
    h2 { margin: 28px 0 8px; font-size: 22px; }
    h3 { margin: 20px 0 8px; font-size: 18px; }
    p, li { color: var(--muted); line-height: 1.65; }
    a { color: var(--link); text-decoration: none; }
    a:hover { text-decoration: underline; }
    nav.breadcrumb { font-size: 14px; margin-top: 6px; }
    .toc { background: var(--card); border:1px solid var(--border); border-radius: 10px; padding: 12px 16px; }
    .toc ul { margin: 8px 0 0 16px; }
    .code { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; background: #0b1220; color: #e2e8f0; padding: 10px 12px; border-radius: 8px; overflow:auto; font-size: 13px; }
    .callout { border-left: 4px solid #818cf8; background: #f5f7ff; padding: 10px 12px; border-radius: 6px; }
    .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(240px, 1fr)); gap: 12px; }
    figure { margin: 0; border: 1px solid var(--border); border-radius: 8px; overflow: hidden; background: #fff; }
    figure img { display:block; width:100%; height:auto; }
    figure figcaption { font-size: 13px; color: var(--muted); padding: 8px 10px; border-top: 1px solid var(--border); }
    footer { padding: 28px 20px; border-top: 1px solid var(--border); color: var(--muted); font-size: 14px; margin-top: 36px; }
    .offsets td, .offsets th { padding: 6px 10px; border-bottom: 1px solid var(--border); text-align: left; font-size: 14px; }
    .offsets { border-collapse: collapse; width: 100%; }
  </style>
</head>
<body>
  <header>
    <div class="container">
      <h1>CS180 Project 1 — Prokudin‑Gorskii Colorizing</h1>
      <nav class="breadcrumb"><a href="../index.html">← Back to Projects</a></nav>
    </div>
  </header>

  <main class="container">
    <section class="toc">
      <strong>Contents:</strong>
      <ul>
        <li><a href="#overview">Project Overview</a></li>
        <li><a href="#part1">Part 1: Single‑Scale Alignment</a></li>
        <li><a href="#results">Results & Offsets</a></li>
        <li><a href="#part2">Part 2: Multi‑Scale Pyramid Alignment</a></li>
      </ul>
    </section>

    <section id="overview">
      <h2>Project Overview</h2>
      <p>
        This project focuses on reconstructing color photographs from the Prokudin‑Gorskii collection.
        The collection contains three separate black‑and‑white images of a scene, each through a different
        color filter: red, green, and blue. The primary challenge is to take these three individual color
        channel images and digitally align them. By correctly layering the red, green, and blue channels,
        we can recreate the full‑color photograph.
      </p>
    </section>

    <section id="part1">
      <h2>Part 1: Single‑Scale Alignment</h2>
      <h3>My Approach</h3>
      <p>
        I split each glass‑plate scan vertically into three equal parts (B, G, R), convert to floats,
        then run an exhaustive window search over shifts for G→B and R→B. For each candidate (dy, dx),
        I compute the overlapping crop of the two channels and score it using either L2 (negative SSE)
        or Normalized Cross‑Correlation (NCC). I also ignore a small inner border in the score to reduce
        edge/border effects. The best shifts are applied via <code>np.roll</code> and the channels are stacked.
      </p>
      <p class="meta">
        Code path: <code>single_scale_search</code> → overlap crops → score (L2/NCC) → choose best →
        <code>np.roll</code> align and save. Helper: <code>single_scale_align</code> wraps IO and printing offsets.
      </p>
    </section>

    

    

    <section id="results">
      <h2>Results & Offsets</h2>
      <p>
        First, single‑scale alignment using L2 (Euclidean distance) on the three small images
        you listed. Offsets are printed as <code>(x, y)</code> where <code>x</code> is row shift
        and <code>y</code> is column shift, matching your notebook prints.
      </p>
      <table class="offsets">
        <thead><tr><th>Image</th><th>G offset (x, y)</th><th>R offset (x, y)</th></tr></thead>
        <tbody>
          <tr><td>monastery.jpg</td><td>(-3, 2)</td><td>(3, 2)</td></tr>
          <tr><td>tobolsk.jpg</td><td>(3, 3)</td><td>(6, 3)</td></tr>
          <tr><td>cathedral.jpg</td><td>(5, 2)</td><td>(12, 3)</td></tr>
        </tbody>
      </table>

      <h3>Single‑Scale (L2) — Thumbnails</h3>
      <div class="grid">
        <figure>
          <img src="output/single_scale_aligned_euclidean_distance_monastery.jpg" alt="Monastery (single-scale L2)" />
          <figcaption>Monastery — Green offset: (-3, 2) · Red offset: (3, 2)</figcaption>
        </figure>
        <figure>
          <img src="output/single_scale_aligned_euclidean_distance_tobolsk.jpg" alt="Tobolsk (single-scale L2)" />
          <figcaption>Tobolsk — Green offset: (3, 3) · Red offset: (6, 3)</figcaption>
        </figure>
        <figure>
          <img src="output/single_scale_aligned_euclidean_distance_cathedral.jpg" alt="Cathedral (single-scale L2)" />
          <figcaption>Cathedral — Green offset: (5, 2) · Red offset: (12, 3)</figcaption>
        </figure>
      </div>
    </section>

    <section id="part2">
      <h2>Part 2: Multi‑Scale Pyramid Alignment</h2>
      <h3>My Approach</h3>
      <p>
        I build a coarse‑to‑fine image pyramid (downscale by 2) for each channel, estimate shifts at the
        coarsest level using the same single‑scale aligner, then iteratively upsample the estimate and refine
        it at each finer level within a small window. I use NCC as the matching metric and pass the scaled
        coarse estimate as the center of the finer‑level search. This handles large displacements efficiently
        on the full‑resolution <code>.tif</code> images.
      </p>
      <p class="meta">Reference: the regular pyramid function before the dedicated “Sobel” section in your notebook.</p>

      <h3>Large Images</h3>

      <table class="offsets">
        <thead><tr><th>Image</th><th>G offset (x, y)</th><th>R offset (x, y)</th></tr></thead>
        <tbody>
          <tr><td>Italil</td><td>(38, 21)</td><td>(76, 35)</td></tr>
          <tr><td>Church</td><td>(25, 4)</td><td>(58, -4)</td></tr>
          <tr><td>Three Generations</td><td>(53, 14)</td><td>(112, 11)</td></tr>
          <tr><td>Lugano</td><td>(41, -16)</td><td>(93, -29)</td></tr>
          <tr><td>Melons</td><td>(82, 11)</td><td>(178, 13)</td></tr>
          <tr><td>Lastochikino</td><td>(-3, -2)</td><td>(75, -9)</td></tr>
          <tr><td>Icon</td><td>(41, 17)</td><td>(89, 23)</td></tr>
          <tr><td>Emir</td><td>(49, 24)</td><td>(155, -1047)</td></tr>
          <tr><td>Siren</td><td>(49, -6)</td><td>(96, -25)</td></tr>
          <tr><td>Self Portrait</td><td>(79, 29)</td><td>(176, 37)</td></tr>
          <tr><td>Harvesters</td><td>(60, 17)</td><td>(124, 13)</td></tr>
        </tbody>
      </table>

      <h3>Thumbnails</h3>
      <div class="grid">
        <figure>
          <img src="output/pyramid_aligned_ncc_italil.jpg" alt="Italil (pyramid + NCC)" />
          <figcaption>Italil — Green: (38, 21) · Red: (76, 35)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_church.jpg" alt="Church (pyramid + NCC)" />
          <figcaption>Church — Green: (25, 4) · Red: (58, -4)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_three_generations.jpg" alt="Three Generations (pyramid + NCC)" />
          <figcaption>Three Generations — Green: (53, 14) · Red: (112, 11)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_lugano.jpg" alt="Lugano (pyramid + NCC)" />
          <figcaption>Lugano — Green: (41, -16) · Red: (93, -29)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_melons.jpg" alt="Melons (pyramid + NCC)" />
          <figcaption>Melons — Green: (82, 11) · Red: (178, 13)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_lastochikino.jpg" alt="Lastochikino (pyramid + NCC)" />
          <figcaption>Lastochikino — Green: (-3, -2) · Red: (75, -9)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_icon.jpg" alt="Icon (pyramid + NCC)" />
          <figcaption>Icon — Green: (41, 17) · Red: (89, 23)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_emir.jpg" alt="Emir (pyramid + NCC)" />
          <figcaption>Emir — Green: (49, 24) · Red: (155, -1047)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_siren.jpg" alt="Siren (pyramid + NCC)" />
          <figcaption>Siren — Green: (49, -6) · Red: (96, -25)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_self_portrait.jpg" alt="Self Portrait (pyramid + NCC)" />
          <figcaption>Self Portrait — Green: (79, 29) · Red: (176, 37)</figcaption>
        </figure>
        <figure>
          <img src="output/pyramid_aligned_ncc_harvesters.jpg" alt="Harvesters (pyramid + NCC)" />
          <figcaption>Harvesters — Green: (60, 17) · Red: (124, 13)</figcaption>
        </figure>
      </div>
    </section>
  </main>

  <footer>
    <div class="container">© Fangzhou — CS180 Project 1</div>
  </footer>
</body>
</html>
